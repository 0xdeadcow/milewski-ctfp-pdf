\begin{quote}
This is part 15 of Categories for Programmers. Previously:
\href{https://bartoszmilewski.com/2015/07/29/representable-functors/}{Representable
Functors}. See the
\href{https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/}{Table
of Contents}.
\end{quote}

Most constructions in category theory are generalizations of results
from other more specific areas of mathematics. Things like products,
coproducts, monoids, exponentials, etc., have been known long before
category theory. They might have been known under different names in
different branches of mathematics. A cartesian product in set theory, a
meet in order theory, a conjunction in logic --- they are all specific
examples of the abstract idea of a categorical product.

The Yoneda lemma stands out in this respect as a sweeping statement
about categories in general with little or no precedent in other
branches of mathematics. Some say that its closest analog is Cayley's
theorem in group theory (every group is isomorphic to a permutation
group of some set).

The setting for the Yoneda lemma is an arbitrary category \emph{C}
together with a functor \code{F} from \emph{C} to \textbf{Set}. We've
seen in the previous section that some \textbf{Set}-valued functors are
representable, that is isomorphic to a hom-functor. The Yoneda lemma
tells us that all \textbf{Set}-valued functors can be obtained from
hom-functors through natural transformations, and it explicitly
enumerates all such transformations.

When I talked about natural transformations, I mentioned that the
naturality condition can be quite restrictive. When you define a
component of a natural transformation at one object, naturality may be
strong enough to ``transport'' this component to another object that is
connected to it through a morphism. The more arrows between objects in
the source and the target categories there are, the more constraints you
have for transporting the components of natural transformations.
\textbf{Set} happens to be a very arrow-rich category.

The Yoneda lemma tells us that a natural transformation between a
hom-functor and any other functor \code{F} is completely determined by
specifying the value of its single component at just one point! The rest
of the natural transformation just follows from naturality conditions.

So let's review the naturality condition between the two functors
involved in the Yoneda lemma. The first functor is the hom-functor. It
maps any object \code{x} in \emph{C} to the set of morphisms
\code{C(a,\ x)} --- for \code{a} a fixed object in \emph{C}. We've
also seen that it maps any morphism \code{f} from \code{x} to
\code{y} to \code{C(a,\ f)}.

The second functor is an arbitrary \textbf{Set}-valued functor
\code{F}.

Let's call the natural transformation between these two functors
\code{α}. Because we are operating in \textbf{Set}, the components of
the natural transformation, like \code{αx} or \code{αy}, are just
regular functions between sets:

\begin{verbatim}
αx :: C(a, x) -> F x αy :: C(a, y) -> F y
\end{verbatim}

\includegraphics[width=2.73958in]{images/yoneda1.png}

And because these are just functions, we can look at their values at
specific points. But what's a point in the set \code{C(a,\ x)}? Here's
the key observation: Every point in the set \code{C(a,\ x)} is also a
morphism \code{h} from \code{a} to \code{x}.

So the naturality square for \code{α}:

\begin{verbatim}
αy ∘ C(a, f) = F f ∘ αx
\end{verbatim}

becomes, point-wise, when acting on \code{h}:

\begin{verbatim}
αy (C(a, f) h) = (F f) (αx h)
\end{verbatim}

You might recall from the previous section that the action of the
hom-functor \code{C(a,-)} on a morphism \code{f} was defined as
precomposition:

\begin{verbatim}
C(a, f) h = f ∘ h
\end{verbatim}

which leads to:

\begin{verbatim}
αy (f ∘ h) = (F f) (αx h)
\end{verbatim}

Just how strong this condition is can be seen by specializing it to the
case of \code{x} equal to \code{a}.

\includegraphics[width=3.12500in]{images/yoneda2.png}

In that case \code{h} becomes a morphism from \code{a} to
\code{a}. We know that there is at least one such morphism,
\code{h\ =\ ida}. Let's plug it in:

\begin{verbatim}
αy f = (F f) (αa ida)
\end{verbatim}

Notice what has just happened: The left hand side is the action of
\code{αy} on an arbitrary element \code{f} of \code{C(a,\ y)}. And
it is totally determined by the single value of \code{αa} at
\code{ida}. We can pick any such value and it will generate a natural
transformation. Since the values of \code{αa} are in the set
\code{F\ a}, any point in \code{F\ a} will define some \code{α}.

Conversely, given any natural transformation \code{α} from
\code{C(a,\ -)} to \code{F}, you can evaluate it at \code{ida} to
get a point in \code{F\ a}.

We have just proven the Yoneda lemma:

There is a one-to-one correspondence between natural transformations
from \code{C(a,\ -)} to \code{F} and elements of \code{F\ a}.

in other words,

\begin{verbatim}
Nat(C(a, -), F) ≅ F a
\end{verbatim}

Or, if we use the notation \code{{[}C,\ Set{]}} for the functor
category between \emph{C} and \textbf{Set}, the set of natural
transformation is just a hom-set in that category, and we can write:

\begin{verbatim}
[C, Set](C(a, -), F) ≅ F a
\end{verbatim}

I'll explain later how this correspondence is in fact a natural
isomorphism.

Now let's try to get some intuition about this result. The most amazing
thing is that the whole natural transformation crystallizes from just
one nucleation site: the value we assign to it at \code{ida}. It
spreads from that point following the naturality condition. It floods
the image of \emph{C} in \textbf{Set}. So let's first consider what the
image of \emph{C} is under \code{C(a,\ -)}.

Let's start with the image of \code{a} itself. Under the hom-functor
\code{C(a,\ -)}, \code{a} is mapped to the set \code{C(a,\ a)}.
Under the functor \code{F}, on the other hand, it is mapped to the set
\code{F\ a}. The component of the natural transformation \code{αa}
is some function from \code{C(a,\ a)} to \code{F\ a}. Let's focus on
just one point in the set \code{C(a,\ a)}, the point corresponding to
the morphism \code{ida}. To emphasize the fact that it's just a point
in a set, let's call it \code{p}. The component \code{αa} should map
\code{p} to some point \code{q} in \code{F\ a}. I'll show you that
any choice of \code{q} leads to a unique natural transformation.

\includegraphics{images/yoneda3.png}

The first claim is that the choice of one point \code{q} uniquely
determines the rest of the function \code{αa}. Indeed, let's pick any
other point, \code{p\'} in \code{C(a,\ a)}, corresponding to
some morphism \code{g} from \code{a} to \code{a}. And here's where
the magic of the Yoneda lemma happens: \code{g} can be viewed as a
point \code{p\'} in the set \code{C(a,\ a)}. At the same time,
it selects two \newterm{functions} between sets. Indeed, under the
hom-functor, the morphism \code{g} is mapped to a function
\code{C(a,\ g)}; and under \code{F} it's mapped to \code{F\ g}.

\includegraphics{images/yoneda4.png}

Now let's consider the action of \code{C(a,\ g)} on our original
\code{p} which, as you remember, corresponds to \code{ida}. It is
defined as precomposition, \code{g∘ida}, which is equal to \code{g},
which corresponds to our point \code{p\'}. So the morphism
\code{g} is mapped to a function that, when acting on \code{p}
produces \code{p\'}, which is \code{g}. We have come full
circle!

Now consider the action of \code{F\ g} on \code{q}. It is some
\code{q\'}, a point in \code{F\ a}. To complete the naturality
square, \code{p\'} must be mapped to \code{q\'} under
\code{αa}. We picked an arbitrary \code{p\'} (an arbitrary
\code{g}) and derived its mapping under \code{αa}. The function
\code{αa} is thus completely determined.

The second claim is that \code{αx} is uniquely determined for any
object \code{x} in \emph{C} that is connected to \code{a}. The
reasoning is analogous, except that now we have two more sets,
\code{C(a,\ x)} and \code{F\ x}, and the morphism \code{g} from
\code{a} to \code{x} is mapped, under the hom-functor, to:

\begin{verbatim}
C(a, g) :: C(a, a) -> C(a, x)
\end{verbatim}

and under \code{F} to:

\begin{verbatim}
F g :: F a -> F x
\end{verbatim}

Again, \code{C(a,\ g)} acting on our \code{p} is given by the
precomposition: \code{g\ ∘\ ida}, which corresponds to a point
\code{p\'} in \code{C(a,\ x)}. Naturality determines the value
of \code{αx} acting on \code{p\'} to be:

\begin{verbatim}
q' = (F g) q
\end{verbatim}

Since \code{p\'} was arbitrary, the whole function \code{αx} is
thus determined.

\includegraphics{images/yoneda5.png}

What if there are objects in \emph{C} that have no connection to
\code{a}? They are all mapped under \code{C(a,\ -)} to a single set
--- the empty set. Recall that the empty set is the initial object in
the category of sets. It means that there is a unique function from this
set to any other set. We called this function \code{absurd}. So here,
again, we have no choice for the component of the natural
transformation: it can only be \code{absurd}.

One way of understanding the Yoneda lemma is to realize that natural
transformations between \textbf{Set}-valued functors are just families
of functions, and functions are in general lossy. A function may
collapse information and it may cover only parts of its codomain. The
only functions that are not lossy are the ones that are invertible ---
the isomorphisms. It follows then that the best structure-preserving
\textbf{Set}-valued functors are the representable ones. They are either
the hom-functors or~the functors that are naturally isomorphic to
hom-functors. Any other functor \code{F} is obtained from a
hom-functor through a lossy transformation. Such a transformation may
not only lose information, but it may also cover only a small part of
the image of the functor \code{F} in \textbf{Set}.

\section{Yoneda in Haskell}\label{yoneda-in-haskell}

We have already encountered the hom-functor in Haskell under the guise
of the reader functor:

\begin{verbatim}
type Reader a x = a -> x
\end{verbatim}

The reader maps morphisms (here, functions) by precomposition:

\begin{verbatim}
instance Functor (Reader a) where fmap f h = f . h
\end{verbatim}

The Yoneda lemma tells us that the reader functor can be naturally
mapped to any other functor.

A natural transformation is a polymorphic function. So given a functor
\code{F}, we have a mapping to it from the reader functor:

\begin{verbatim}
alpha :: forall x . (a -> x) -> F x
\end{verbatim}

As usual, \code{forall} is optional, but I like to write it explicitly
to emphasize parametric polymorphism of natural transformations.

The Yoneda lemma tells us that these natural transformations are in
one-to-one correspondence with the elements of \code{F\ a}:

\begin{verbatim}
forall x . (a -> x) -> F x ≅ F a
\end{verbatim}

The right hand side of this identity is what we would normally consider
a data structure. Remember the interpretation of functors as generalized
containers? \code{F\ a} is a container of \code{a}. But the left
hand side is a polymorphic function that takes a function as an
argument. The Yoneda lemma tells us that the two representations are
equivalent --- they contain the same information.

Another way of saying this is: Give me a polymorphic function of the
type:

\begin{verbatim}
alpha :: forall x . (a -> x) -> F x
\end{verbatim}

and I'll produce a container of \code{a}. The trick is the one we used
in the proof of the Yoneda lemma: we call this function with \code{id}
to get an element of \code{F\ a}:

\begin{verbatim}
alpha id :: F a
\end{verbatim}

The converse is also true: Given a value of the type \code{F\ a}:

\begin{verbatim}
fa :: F a
\end{verbatim}

one can define a polymorphic function:

\begin{verbatim}
alpha h = fmap h fa
\end{verbatim}

of the correct type. You can easily go back and forth between the two
representations.

The advantage of having multiple representations is that one might be
easier to compose than the other, or that one might be more efficient in
some applications than the other.

The simplest illustration of this principle is the code transformation
that is often used in compiler construction: the continuation passing
style or CPS. It's the simplest application of the Yoneda lemma to the
identity functor. Replacing \code{F} with identity produces:

\begin{verbatim}
forall r . (a -> r) -> r ≅ a
\end{verbatim}

The interpretation of this formula is that any type \code{a} can be
replaced by a function that takes a ``handler'' for \code{a}. A
handler is a function accepting \code{a} and performing the rest of
the computation --- the continuation. (The type \code{r} usually
encapsulates some kind of status code.)

This style of programming is very common in UIs, in asynchronous
systems, and in concurrent programming. The drawback of CPS is that it
involves inversion of control. The code is split between producers and
consumers (handlers), and is not easily composable. Anybody who's done
any amount of nontrivial web programming is familiar with the nightmare
of spaghetti code from interacting stateful handlers. As we'll see
later, judicious use of functors and monads can restore some
compositional properties of CPS.

\section{Co-Yoneda}\label{co-yoneda}

As usual, we get a bonus construction by inverting the direction of
arrows. The Yoneda lemma can be applied to the opposite category
\emph{C}\textsuperscript{op} to give us a mapping between contravariant
functors.

Equivalently, we can derive the co-Yoneda lemma by fixing the target
object of our hom-functors instead of the source. We get the
contravariant hom-functor from \emph{C} to \textbf{Set}:
\code{C(-,\ a)}. The contravariant version of the Yoneda lemma
establishes one-to-one correspondence between natural transformations
from this functor to any other contravariant functor \code{F} and the
elements of the set \code{F\ a}:

\begin{verbatim}
Nat(C(-, a), F) ≅ F a
\end{verbatim}

Here's the Haskell version of the co-Yoneda lemma:

\begin{verbatim}
forall x . (x -> a) -> F x ≅ F a
\end{verbatim}

Notice that in some literature it's the contravariant version that's
called the Yoneda lemma.

\section{Challenges}\label{challenges}

\begin{enumerate}
\item
  Show that the two functions \code{phi} and \code{psi} that form
  the Yoneda isomorphism in Haskell are inverses of each other.

\begin{verbatim}
phi :: (forall x . (a -> x) -> F x) -> F a phi alpha = alpha id
\end{verbatim}

\begin{verbatim}
psi :: F a -> (forall x . (a -> x) -> F x) psi fa h = fmap h fa
\end{verbatim}
\item
  A discrete category is one that has objects but no morphisms other
  than identity morphisms. How does the Yoneda lemma work for functors
  from such a category?
\item
  A list of units \code{{[}(){]}} contains no other information but
  its length. So, as a data type, it can be considered an encoding of
  integers. An empty list encodes zero, a singleton \code{{[}(){]}} (a
  value, not a type) encodes one, and so on. Construct another
  representation of this data type using the Yoneda lemma for the list
  functor.
\end{enumerate}

\section{Bibliography}\label{bibliography}

Next:
\href{https://bartoszmilewski.com/2015/10/28/yoneda-embedding/}{Yoneda
Embedding}.

\section{Acknowledgments}\label{acknowledgments}

I'd like to thank Gershom Bazerman for checking my math and logic, and
André van Meulebrouck, who has been volunteering his editing help
throughout this series of posts.\\
\href{https://twitter.com/BartoszMilewski}{Follow @BartoszMilewski}
